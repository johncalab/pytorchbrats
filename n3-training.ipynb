{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dataset\n",
    "* training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset class\n",
    "Pytorch has built-in Dataset and DataLoader classes, which help to feed tensors to networks.  \n",
    "For Dataset you need to provide the `len` and `getitem` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class brats3dDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Needs a rootPath.\n",
    "    Expects to find 'source' and 'target' folders.\n",
    "    Expects to deal with preprocessed numpy files.\n",
    "    \"\"\"\n",
    "    def __init__(self, rootPath):\n",
    "        self.source = []\n",
    "        self.target = []\n",
    "        # perhaps a pandas Series would be better than an array?\n",
    "        \n",
    "        pathSource = os.path.join(rootPath, 'source')\n",
    "        imgPaths = os.listdir(pathSource)\n",
    "        for path in imgPaths:\n",
    "            if path.endswith('.npy'):\n",
    "                self.source.append(os.path.join(pathSource, path))\n",
    "        \n",
    "        pathTarget = os.path.join(rootPath, 'target')\n",
    "        imgPaths = os.listdir(pathTarget)\n",
    "        for path in imgPaths:\n",
    "            if path.endswith('.npy'):\n",
    "                self.target.append(os.path.join(pathTarget, path))\n",
    "        \n",
    "    def __len__(self):\n",
    "        assert len(self.source) == len(self.target)\n",
    "        return len(self.source)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        x = np.load(self.source[idx])\n",
    "        x = torch.from_numpy(x)\n",
    "        x = x.float()\n",
    "        \n",
    "        y = np.load(self.target[idx])\n",
    "        y = torch.from_numpy(y)\n",
    "        y = y.float()\n",
    "        \n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath = os.path.join('ignore', 'data', 'numpyData32')\n",
    "alldata = brats3dDataset(rootPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "torch.Size([4, 32, 32, 64])\n",
      "torch.Size([32, 32, 64])\n"
     ]
    }
   ],
   "source": [
    "print(len(alldata))\n",
    "x,y = alldata.__getitem__(2)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 32, 32, 64]) torch.float32 cpu\n",
      "torch.Size([4, 32, 32, 64]) torch.float32 cpu\n",
      "torch.Size([4, 4, 32, 32, 64]) torch.float32 cpu\n",
      "torch.Size([4, 32, 32, 64]) torch.float32 cpu\n",
      "torch.Size([4, 4, 32, 32, 64]) torch.float32 cpu\n",
      "torch.Size([4, 32, 32, 64]) torch.float32 cpu\n",
      "Training done.\n",
      "\n",
      "torch.Size([3, 4, 32, 32, 64]) torch.float32 cpu\n",
      "torch.Size([3, 32, 32, 64]) torch.float32 cpu\n",
      "Validation done.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "SPLIT_FRAC = 0.25\n",
    "valid_size = int(0.25*len(alldata))\n",
    "train_size = len(alldata) - valid_size\n",
    "train_data, valid_data = random_split(alldata,[train_size,valid_size])\n",
    "\n",
    "BATCH_LEN = 4\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_LEN, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=BATCH_LEN, shuffle=True)\n",
    "\n",
    "for x,y in train_loader:\n",
    "    print(x.shape,x.dtype,x.device)\n",
    "    print(y.shape,x.dtype,y.device)\n",
    "print('Training done.\\n')\n",
    "for x,y in valid_loader:\n",
    "    print(x.shape,x.dtype,x.device)\n",
    "    print(y.shape,x.dtype,y.device)\n",
    "print('Validation done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i would like for the end result to look like this\n",
    "* Initialize model.\n",
    "* Nood\n",
    "Need:\n",
    "* training helper function\n",
    "* evaluating helper function\n",
    "* write_to_log function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To be used when training a model from scratch.\n",
    "\"\"\"\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "from themodel import SmallU3D\n",
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# parser\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-d', '--dataPath', type=str, default='data')\n",
    "parser.add_argument('-ne', '--numEpochs', type=int, default=3)\n",
    "parser.add_argument('-bs', '--batchSize', type=int, default=16)\n",
    "parser.add_argument('-t', '--threshold', type=float, default=0.5, help='Threshold for the Sigmoid')\n",
    "parser.add_argument('--cuda', type=bool, default=False)\n",
    "parser.add_argument('--resolution', type=str, default='32', help='Which resolution to use.')\n",
    "parser.add_argument('--plot', type=bool,default=True)\n",
    "parser.add_argument('--loss', type=str, default='BCE')\n",
    "parser.add_argument('--lr', type=float, default=0.001)\n",
    "\n",
    "# add learning rate\n",
    "# add valid split\n",
    "args = parser.parse_args()\n",
    "dataPath = args.dataPath\n",
    "#NUM_WORKERS = args.numWorkers\n",
    "NUM_EPOCHS = args.numEpochs\n",
    "BATCH_SIZE = args.batchSize\n",
    "SPLIT_FRAC = 0.25\n",
    "LEARNING_RATE = args.lr\n",
    "THRESHOLD = args.threshold\n",
    "RESOLUTION = args.resolution\n",
    "LOSS = args.loss\n",
    "\n",
    "print('dataPath =', dataPath)\n",
    "#print('NumWorkrs =', NUM_WORKERS)\n",
    "print(f'NumEpochs = {NUM_EPOCHS}')\n",
    "print(f'BatchSize = {BATCH_SIZE}')\n",
    "print(f'SPLIT_FRAC = {SPLIT_FRAC}')\n",
    "\n",
    "\n",
    "# to be set by the parser\n",
    "VERBOSE = True\n",
    "\n",
    "\n",
    "\n",
    "# Get data\n",
    "fullDataset = bratsDataset(dataPath,RESOLUTION)\n",
    "print(f\"There are {len(fullDataset)} images in total.\")\n",
    "\n",
    "# Split into training and validation\n",
    "valid_size = int(SPLIT_FRAC * len(fullDataset))\n",
    "train_size = len(fullDataset) - valid_size\n",
    "train_dataset, valid_dataset = random_split(fullDataset, [train_size, valid_size])\n",
    "print(f\"There are {len(train_dataset)} training images, and {len(valid_dataset)} validation images.\")\n",
    "\n",
    "# Load data\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Use model from themodel.py\n",
    "device = 'cpu'\n",
    "if args.cuda and torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "\n",
    "\n",
    "# model, optimizer, loss function\n",
    "torchDevice = torch.device(device)\n",
    "model = SmallU3D().to(torchDevice)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "if args.loss == 'dice':\n",
    "    from themodel import diceLossModule\n",
    "    criterion = diceLossModule()\n",
    "else:\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "# Here starts the training\n",
    "print(\"\\nAll right, let's do this.\")\n",
    "\n",
    "epochMeanLosses = []\n",
    "epochMeanScores = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # print(f'This is epoch number {epoch}.')\n",
    "    print(f'\\n-------Epoch {epoch+1}-------')\n",
    "\n",
    "    # training loop----\n",
    "    print('\\n*Training')\n",
    "    model.train()\n",
    "    losses = []\n",
    "    batchloop = tqdm.tqdm(train_dataloader)\n",
    "    scores = []\n",
    "    for x,y in batchloop:\n",
    "        # use cuda if available\n",
    "        x = x.to(torchDevice)\n",
    "        y = y.to(torchDevice)\n",
    "        # Forward pass\n",
    "        y_pred = model(x)\n",
    "        # Compute loss\n",
    "        loss = criterion(y_pred,y)\n",
    "        # Kill gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # update gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        batchloop.set_description(f\"Epoch number {epoch+1}, Loss: {loss.item()}\")\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        score = iouscore(y_pred,y)\n",
    "        scores.append(score)\n",
    "\n",
    "    print(f\"I trained on {len(losses)} images. The average training loss was {np.asarray(losses).mean()}.\\n\")\n",
    "    print(f\"The average training score was {np.asarray(scores).mean()}.\\n\")\n",
    "\n",
    "    # validation loop----\n",
    "    print('\\n*Validation')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        losses = []\n",
    "        scores = []\n",
    "        validloop = tqdm.tqdm(valid_dataloader)\n",
    "        for x,y in validloop:\n",
    "            x = x.to(torchDevice)\n",
    "            y = y.to(torchDevice)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred,y)\n",
    "            losses.append(loss.item())\n",
    "            validloop.set_description('Loss: {}'.format(loss.item()))\n",
    "\n",
    "            score = iouscore(y_pred,y)\n",
    "            scores.append(score)\n",
    "\n",
    "        print(f\"I evaluated the model on {len(scores)} images\")\n",
    "        \n",
    "        epochMeanLoss = np.asarray(losses).mean().item()\n",
    "        print(f\"The avg validation loss is {epochMeanLoss}.\")\n",
    "        epochMeanLosses.append(epochMeanLoss)\n",
    "\n",
    "        epochMeanScore = np.asarray(scores).mean().item()\n",
    "        print(f\"The avg IoU score is: {epochMeanScore}.\")\n",
    "        epochMeanScores.append(epochMeanScore)\n",
    "\n",
    "        # save/overwrite losses and scores\n",
    "        np.save('losses', epochMeanLosses)\n",
    "        np.save('scores',epochMeanScores)\n",
    "\n",
    "print('\\nWhile validating, these were the mean losses:\\n')\n",
    "print(epochMeanLosses)\n",
    "print('\\nWhile validating, these were the mean scores:\\n')\n",
    "print(epochMeanScores)\n",
    "print(\"\\nI am saving the current model now.\")\n",
    "torch.save(model.state_dict(), 'model.pt')\n",
    "\n",
    "if args.plot:\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(epochMeanLosses)\n",
    "    plt.plot(epochMeanScores)\n",
    "    plt.show()\n",
    "\n",
    "# To reload it: \n",
    "# model = myModel()\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
