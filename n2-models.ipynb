{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersection over Union\n",
    "![](extra/iou.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class iou_module(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(iou_module,self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y):\n",
    "        loss = iou_loss(y_pred, y)\n",
    "        return loss\n",
    "    \n",
    "def iou_score(y_pred, y, SMOOTH=1e-6, rounding=False):\n",
    "    \"\"\"\n",
    "    aka Jaccard\n",
    "    expect: y_pred, y to be of SAME integer type\n",
    "    \n",
    "    y_pred is output of model\n",
    "        expect: y_pred.shape = (batch_len,D,D,S)\n",
    "        (no channels!)\n",
    "    y is truth value (labels)\n",
    "        expect: y.shape = (batch_len,D,D,S)\n",
    "    \n",
    "    returns: the mean across the batch of the iou scores\n",
    "    \"\"\"\n",
    "    # sanity check\n",
    "    assert y_pred.shape == y.shape\n",
    "    # to compute scores, we sum along all axes except for batch\n",
    "    axes = tuple([i for i in range(1,len(y.shape))])\n",
    "    batch_len = y.shape[0]\n",
    "    # if y_pred hasn't been rounded\n",
    "    if rounding:\n",
    "        y_pred = y_pred.round()\n",
    "    \n",
    "    intersection = (y_pred & y).sum(dim=axes).float()\n",
    "    union = (y_pred | y).sum(dim=axes).float()\n",
    "    # sanity check\n",
    "    assert intersection.shape == union.shape\n",
    "    assert union.shape == (batch_len,)\n",
    "    \n",
    "    iou = 1 - (intersection + SMOOTH) / (union + SMOOTH)\n",
    "    \n",
    "    return iou.mean()\n",
    "\n",
    "def iou_loss(y_pred, y, SMOOTH=1e-6):\n",
    "    \"\"\"\n",
    "    essentially returns 1 - iou_score\n",
    "    but takes care of y_pred not being rounded\n",
    "    \"\"\"\n",
    "    assert y_pred.shape == y.shape\n",
    "    axes = tuple([i for i in range(1,len(y.shape))])\n",
    "    batch_len = y.shape[0]\n",
    "    \n",
    "    numerator = y*y_pred\n",
    "    numerator = numerator.sum(dim=axes)\n",
    "    a = y.sum(dim=axes)\n",
    "    b = y.sum(dim=axes)\n",
    "    denominator = a + b - numerator\n",
    "    quotient = (numerator + SMOOTH) / (denominator + SMOOTH)\n",
    "    return quotient.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulator(model,criterion,score_fun,batch_len=1,C=4,D=32,S=64,sigm=True):\n",
    "    \"\"\"\n",
    "    Creates source data x of shape (batch_len,C,D,D,S).\n",
    "    Creates target data y of shape (batch_len,D,D,S).\n",
    "    Creates prediction data y_pred using model(x).\n",
    "    Computes loss using criterion(y_pred,y).\n",
    "        NOTE: the order of arguments may matter.\n",
    "    \"\"\"\n",
    "    # simulate input data\n",
    "    x = torch.randn(batch_len,C,D,D,S)\n",
    "    print(f\"Input has shape {tuple(x.shape)}.\")\n",
    "    # simulate output data\n",
    "    y = torch.randn(batch_len,D,D,S)\n",
    "    y = torch.sigmoid(y).round()\n",
    "    print(f\"Target has shape {tuple(y.shape)}.\")\n",
    "    # simulate prediction for training\n",
    "    y_pred = model(x)\n",
    "    print(f\"Training output has shape {tuple(y_pred.shape)}.\")\n",
    "    # compute loss\n",
    "    if sigm:\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "    loss = criterion(y_pred,y)\n",
    "    print(f\"Loss is {loss.item()}.\")\n",
    "    \n",
    "    loss.backward()\n",
    "    print(\"Backward pass works.\")\n",
    "    \n",
    "    # simulate prediction for evaluating\n",
    "    y_pred = model(x)\n",
    "    if sigm:\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "    y_pred = y_pred.round()\n",
    "    print(f\"Evaluation output has shape {tuple(y_pred.shape)}.\")\n",
    "    # convert to int type\n",
    "    # x.byte() is equivalent to x.to(dtype=torch.uint8)\n",
    "    # https://pytorch.org/docs/stable/tensors.html\n",
    "    y_pred = y_pred.byte()\n",
    "    y = y.byte()\n",
    "    score = score_fun(y_pred,y).item()\n",
    "    print(f\"Score is {score}.\")\n",
    "\n",
    "    # simulate segmentation comparison\n",
    "    y_pred = y_pred[0].cpu().detach().numpy()\n",
    "    y = y[0].cpu().detach().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(y_pred[:,:,35])\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(y[:,:,35])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pixel-by-pixel logistic regression (bad for your health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixelwise Logistic Regression (don't run)\n",
    "class PixLog(nn.Module):\n",
    "    def __init__(self,C=4,D=32,S=64):\n",
    "        super(PixLog,self).__init__()\n",
    "        \n",
    "        self.dimensions = (C,D,D,S)\n",
    "        self.fc = nn.Linear(in_features=C*D*D*S, out_features=D*D*S,bias=True)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x_in):\n",
    "        batch_len = x_in.shape[0]\n",
    "        x = x_in.view(batch_len,-1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        dummy_dim = (-1,) + self.dimensions[1:]\n",
    "        x_out = x.view(dummy_dim)\n",
    "        return x_out\n",
    "    \n",
    "# If you even try to initialize this, you're gonna have a bad time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input has shape (1, 4, 32, 32, 64).\n",
      "Target has shape (1, 32, 32, 64).\n",
      "Training output has shape (1, 32, 32, 64).\n",
      "Loss is 0.3334220051765442.\n",
      "Backward pass works.\n",
      "Evaluation output has shape (1, 32, 32, 64).\n",
      "Score is 0.6662187576293945.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a simple encoderdecoder-type model\n",
    "class Crush(nn.Module):\n",
    "    def __init__(self,D=32,S=64,C=4,crush_size=32):\n",
    "        super(Crush,self).__init__()\n",
    "        \n",
    "        self.dimensions = (C,D,D,S)\n",
    "        self.in_features = int(D*D*S*C)\n",
    "        self.crush = crush_size\n",
    "        self.out_features = int(D*D*S)\n",
    "        self.enc = nn.Linear(in_features=self.in_features,out_features=self.crush,bias=True)\n",
    "        self.act = nn.ReLU()\n",
    "        self.dec = nn.Linear(in_features=self.crush,out_features=self.out_features)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x_in):\n",
    "        batch_len = x_in.shape[0]\n",
    "        x = x_in.view(batch_len,-1)\n",
    "        x = self.enc(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dec(x)\n",
    "        \n",
    "        dummy_dim = (-1,) + self.dimensions[1:]\n",
    "        x_out = x.view(dummy_dim)\n",
    "        return x_out\n",
    "\n",
    "model = Crush()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "simulator(model=model,criterion=iou_module(),score_fun=iou_score)\n",
    "# simulator(model=model,criterion=nn.BCEWithLogitsLoss(),score_fun=iou_score,sigm=False)\n",
    "# for loss = nn.BCEWithLogitsLoss()\n",
    "# should be of the form loss(y_pred,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Sequential CNN\n",
    "* 4 Convolution layers  \n",
    "![](extra/conv.gif)  \n",
    "Image from:\n",
    "https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
    "* ReLU activation\n",
    "* Batch normalization  \n",
    "![](extra/batchnorm.png)  \n",
    "Image from:\n",
    "https://medium.com/luminovo/a-refresher-on-batch-re-normalization-5e0a1e902960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input has shape (1, 4, 32, 32, 64).\n",
      "Target has shape (1, 32, 32, 64).\n",
      "Training output has shape (1, 32, 32, 64).\n",
      "Loss is 0.33152925968170166.\n",
      "Backward pass works.\n",
      "Evaluation output has shape (1, 32, 32, 64).\n",
      "Score is 0.7280170917510986.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a simple sequence of convolutional layers\n",
    "class ConvSeq(nn.Module):\n",
    "    def __init__(self,input_channels=4):\n",
    "        super(ConvSeq,self).__init__()\n",
    "        \n",
    "        self.input_channels = input_channels\n",
    "        \n",
    "        self.c1 = self.ConvLayer(in_channels=self.input_channels)\n",
    "        self.c2 = self.ConvLayer()\n",
    "        self.c3 = self.ConvLayer()\n",
    "        self.cfinal = self.ConvLayer(out_channels=1, relu=False)\n",
    "    \n",
    "    def forward(self, x_in):\n",
    "        x = self.c1(x_in)\n",
    "        x = self.c2(x)\n",
    "        x = self.c3(x)\n",
    "        x_out = self.cfinal(x).squeeze(1)\n",
    "                    \n",
    "        return x_out\n",
    "    \n",
    "    def ConvLayer(self, in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1, bias=True, relu=True):\n",
    "        layer = nn.Sequential()\n",
    "        conv = nn.Conv3d(in_channels=in_channels,\n",
    "                         out_channels=out_channels,\n",
    "                         kernel_size=kernel_size,\n",
    "                         padding=padding,\n",
    "                         bias=bias)\n",
    "        layer.add_module('conv',conv)\n",
    "        if relu:\n",
    "            layer.add_module('relu',nn.ReLU())\n",
    "\n",
    "        return layer\n",
    "\n",
    "model = ConvSeq()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = iou_module()\n",
    "simulator(model=model,criterion=criterion,score_fun=iou_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow 3d U-net\n",
    "* Original U-net paper https://arxiv.org/abs/1505.04597\n",
    "* The skip connection concatenates tensors channel-wise.\n",
    "* Downsampling is MaxPool.  \n",
    "![](extra/maxpool.webp)\n",
    "* Upsampling is nearest neighbor. https://pytorch.org/docs/master/nn.functional.html#interpolate  \n",
    "![](extra/upsample.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input has shape (1, 4, 32, 32, 64).\n",
      "Target has shape (1, 32, 32, 64).\n",
      "Training output has shape (1, 32, 32, 64).\n",
      "Loss is 0.33342114090919495.\n",
      "Backward pass works.\n",
      "Evaluation output has shape (1, 32, 32, 64).\n",
      "Score is 0.7533161640167236.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# small 3d u-net with concatenating skip connection\n",
    "class Small3dUcat(nn.Module):\n",
    "    def __init__(self,input_channels=4,num_filters=32):\n",
    "        super(Small3dUcat,self).__init__()\n",
    "        \n",
    "        # Structure:\n",
    "        # Conv,Conv,MaxPool,Conv,Conv,UnPool,Conv,Conv\n",
    "        \n",
    "        self.input_channels = input_channels\n",
    "        self.num_filters = num_filters\n",
    "        \n",
    "        self.c1 = self.ConvLayer(in_channels=self.input_channels,out_channels=num_filters)\n",
    "        self.c2 = self.ConvLayer(in_channels=num_filters,out_channels=num_filters)\n",
    "\n",
    "        self.c3 = self.ConvLayer(in_channels=num_filters,out_channels=num_filters)\n",
    "        self.c4 = self.ConvLayer(in_channels=num_filters,out_channels=num_filters)\n",
    "        \n",
    "        self.c5 = self.ConvLayer(in_channels=2*num_filters,out_channels=num_filters)\n",
    "        self.c6 = self.ConvLayer(in_channels=num_filters,out_channels=num_filters)\n",
    "        self.c7 = self.ConvLayer(in_channels=num_filters,out_channels=1)\n",
    "    \n",
    "    def forward(self, x_in):\n",
    "        x1 = self.c1(x_in)\n",
    "        x1 = self.c2(x1)\n",
    "        \n",
    "        x2 = F.max_pool3d(x1,kernel_size=2)\n",
    "        x2 = self.c3(x2)\n",
    "        x2 = self.c4(x2)\n",
    "        \n",
    "        x2 = F.interpolate(x2, scale_factor=2)\n",
    "        # concatenate x1,x2\n",
    "        x = torch.cat([x1,x2],dim=1)\n",
    "        x = self.c5(x)\n",
    "        x = self.c6(x)\n",
    "        x = self.c7(x)\n",
    "        \n",
    "        x_out = x.squeeze(1)\n",
    "\n",
    "        return x_out\n",
    "    \n",
    "    def ConvLayer(self, in_channels=32, out_channels=32, kernel_size=3,\n",
    "                  stride=1, padding=1, bias=True, relu=True, batchnorm=True):\n",
    "        layer = nn.Sequential()\n",
    "        conv = nn.Conv3d(in_channels=in_channels,\n",
    "                         out_channels=out_channels,\n",
    "                         kernel_size=kernel_size,\n",
    "                         padding=padding,\n",
    "                         bias=bias)\n",
    "        layer.add_module('conv',conv)\n",
    "        if relu:\n",
    "            layer.add_module('relu',nn.ReLU())\n",
    "        if batchnorm:\n",
    "            layer.add_module('batchnorm',nn.BatchNorm3d(out_channels))\n",
    "\n",
    "        return layer\n",
    "\n",
    "model = Small3dUcat()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = iou_module()\n",
    "simulator(model=model,criterion=criterion,score_fun=iou_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow 3d U-net again\n",
    "* Same as above except skip connection adds tensors instead of concatenating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input has shape (1, 4, 32, 32, 64).\n",
      "Target has shape (1, 32, 32, 64).\n",
      "Training output has shape (1, 32, 32, 64).\n",
      "Loss is 0.330346941947937.\n",
      "Backward pass works.\n",
      "Evaluation output has shape (1, 32, 32, 64).\n",
      "Score is 0.7519700527191162.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# small 3d u-net with addition skip connection\n",
    "class Small3dUadd(nn.Module):\n",
    "    def __init__(self,input_channels=4,num_filters=32):\n",
    "        super(Small3dUadd,self).__init__()\n",
    "        \n",
    "        # Structure:\n",
    "        # Conv,Conv,MaxPool,Conv,Conv,UnPool,Conv,Conv\n",
    "        \n",
    "        self.input_channels = input_channels\n",
    "        self.num_filters = num_filters\n",
    "        \n",
    "        self.c1 = self.ConvLayer(in_channels=self.input_channels,out_channels=num_filters)\n",
    "        self.c2 = self.ConvLayer(in_channels=num_filters,out_channels=num_filters)\n",
    "\n",
    "        self.c3 = self.ConvLayer(in_channels=num_filters,out_channels=num_filters)\n",
    "        self.c4 = self.ConvLayer(in_channels=num_filters,out_channels=num_filters)\n",
    "        \n",
    "        self.c5 = self.ConvLayer(in_channels=num_filters,out_channels=num_filters)\n",
    "        self.c6 = self.ConvLayer(in_channels=num_filters,out_channels=num_filters)\n",
    "        self.c7 = self.ConvLayer(in_channels=num_filters,out_channels=1)\n",
    "    \n",
    "    def forward(self, x_in, evaluating=False):\n",
    "        x1 = self.c1(x_in)\n",
    "        x1 = self.c2(x1)\n",
    "        \n",
    "        x2 = F.max_pool3d(x1,kernel_size=2)\n",
    "        x2 = self.c3(x2)\n",
    "        x2 = self.c4(x2)\n",
    "        \n",
    "        x2 = F.interpolate(x2, scale_factor=2)\n",
    "        # add x1,x2\n",
    "        x = F.relu(x1+x2)\n",
    "        x = self.c5(x)\n",
    "        x = self.c6(x)\n",
    "        x = self.c7(x)\n",
    "        \n",
    "        x_out = x.squeeze(1)\n",
    "\n",
    "        return x_out\n",
    "    \n",
    "    def ConvLayer(self, in_channels=32, out_channels=32, kernel_size=3,\n",
    "                  stride=1, padding=1, bias=True, relu=True, batchnorm=True):\n",
    "        layer = nn.Sequential()\n",
    "        conv = nn.Conv3d(in_channels=in_channels,\n",
    "                         out_channels=out_channels,\n",
    "                         kernel_size=kernel_size,\n",
    "                         padding=padding,\n",
    "                         bias=bias)\n",
    "        layer.add_module('conv',conv)\n",
    "        if relu:\n",
    "            layer.add_module('relu',nn.ReLU())\n",
    "        if batchnorm:\n",
    "            layer.add_module('batchnorm',nn.BatchNorm3d(out_channels))\n",
    "\n",
    "        return layer\n",
    "\n",
    "model = Small3dUadd()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = iou_module()\n",
    "simulator(model=model,criterion=criterion,score_fun=iou_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A proper U-net.\n",
    "![](extra/u.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input has shape (1, 4, 32, 32, 64).\n",
      "Target has shape (1, 32, 32, 64).\n",
      "Training output has shape (1, 32, 32, 64).\n",
      "Loss is 0.33333519101142883.\n",
      "Backward pass works.\n",
      "Evaluation output has shape (1, 32, 32, 64).\n",
      "Score is 0.7699887156486511.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a proper U-net\n",
    "class Unet3d(nn.Module):\n",
    "    def __init__(self,input_channels=4,num_filters=64):\n",
    "        super(Unet3d,self).__init__()\n",
    "        \n",
    "        # Structure:\n",
    "        # cccmcccmcccmcccmcccucccucccucccucccf\n",
    "        \n",
    "        self.input_channels = input_channels\n",
    "        c = self.input_channels\n",
    "        self.num_filters = num_filters\n",
    "        n = self.num_filters\n",
    "        \n",
    "        # down\n",
    "        self.c1 = self.ConvLayer(in_channels=c,out_channels=n)\n",
    "        self.c2 = self.ConvLayer(in_channels=n,out_channels=n)\n",
    "        self.c3 = self.ConvLayer(in_channels=n,out_channels=n)\n",
    "\n",
    "        self.c4 = self.ConvLayer(in_channels=n,out_channels=2*n)\n",
    "        self.c5 = self.ConvLayer(in_channels=2*n,out_channels=2*n)\n",
    "        self.c6 = self.ConvLayer(in_channels=2*n,out_channels=2*n)\n",
    "\n",
    "        self.c7 = self.ConvLayer(in_channels=2*n,out_channels=4*n)\n",
    "        self.c8 = self.ConvLayer(in_channels=4*n,out_channels=4*n)\n",
    "        self.c9 = self.ConvLayer(in_channels=4*n,out_channels=4*n)\n",
    "\n",
    "        self.c10 = self.ConvLayer(in_channels=4*n,out_channels=8*n)\n",
    "        self.c11 = self.ConvLayer(in_channels=8*n,out_channels=8*n)\n",
    "        self.c12 = self.ConvLayer(in_channels=8*n,out_channels=8*n)\n",
    "\n",
    "        self.c13 = self.ConvLayer(in_channels=8*n,out_channels=16*n)\n",
    "        self.c14 = self.ConvLayer(in_channels=16*n,out_channels=16*n)\n",
    "        self.c15 = self.ConvLayer(in_channels=16*n,out_channels=16*n)\n",
    "        \n",
    "        # up\n",
    "        self.c16 = self.ConvLayer(in_channels=16*n+8*n,out_channels=8*n)\n",
    "        self.c17 = self.ConvLayer(in_channels=8*n,out_channels=8*n)\n",
    "        self.c18 = self.ConvLayer(in_channels=8*n,out_channels=8*n)\n",
    "\n",
    "        \n",
    "        self.c19 = self.ConvLayer(in_channels=8*n+4*n,out_channels=4*n)\n",
    "        self.c20 = self.ConvLayer(in_channels=4*n,out_channels=4*n)\n",
    "        self.c21 = self.ConvLayer(in_channels=4*n,out_channels=4*n)\n",
    "\n",
    "        \n",
    "        self.c22 = self.ConvLayer(in_channels=4*n+2*n,out_channels=2*n)\n",
    "        self.c23 = self.ConvLayer(in_channels=2*n,out_channels=2*n)\n",
    "        self.c24 = self.ConvLayer(in_channels=2*n,out_channels=2*n)\n",
    "\n",
    "        self.c25 = self.ConvLayer(in_channels=2*n+n,out_channels=n)\n",
    "        self.c26 = self.ConvLayer(in_channels=n,out_channels=n)\n",
    "        self.c27 = self.ConvLayer(in_channels=n,out_channels=n)\n",
    "        \n",
    "        self.f = self.ConvLayer(in_channels=n,out_channels=1,\n",
    "                                kernel_size=1,padding=0)\n",
    "\n",
    "    def forward(self, x_in, evaluating=False):\n",
    "        x = self.c1(x_in)\n",
    "        x = self.c2(x)\n",
    "        x3 = self.c3(x)\n",
    "        \n",
    "        x = F.max_pool3d(x3,kernel_size=2)\n",
    "        x = self.c4(x)\n",
    "        x = self.c5(x)\n",
    "        x6 = self.c6(x)\n",
    "        \n",
    "        x = F.max_pool3d(x6,kernel_size=2)\n",
    "        x = self.c7(x)\n",
    "        x = self.c8(x)\n",
    "        x9 = self.c9(x)\n",
    "        \n",
    "        x = F.max_pool3d(x9,kernel_size=2)\n",
    "        x = self.c10(x)\n",
    "        x = self.c11(x)\n",
    "        x12 = self.c12(x)\n",
    "        \n",
    "        x = F.max_pool3d(x12,kernel_size=2)\n",
    "        x = self.c13(x)\n",
    "        x = self.c14(x)\n",
    "        x = self.c15(x)\n",
    "        \n",
    "        x = F.interpolate(x, scale_factor=2)\n",
    "        x = torch.cat([x,x12],dim=1)\n",
    "        x = self.c16(x)\n",
    "        x = self.c17(x)\n",
    "        x = self.c18(x)\n",
    "        \n",
    "        x = F.interpolate(x,scale_factor=2)\n",
    "        x = torch.cat([x,x9],dim=1)\n",
    "        x = self.c19(x)\n",
    "        x = self.c20(x)\n",
    "        x = self.c21(x)\n",
    "        \n",
    "        x = F.interpolate(x,scale_factor=2)\n",
    "        x = torch.cat([x,x6],dim=1)\n",
    "        x = self.c22(x)\n",
    "        x = self.c23(x)\n",
    "        x = self.c24(x)\n",
    "        \n",
    "        x = F.interpolate(x,scale_factor=2)\n",
    "        x = torch.cat([x,x3],dim=1)\n",
    "        x = self.c25(x)\n",
    "        x = self.c26(x)\n",
    "        x = self.c27(x)\n",
    "        \n",
    "        x = self.f(x)\n",
    "        x_out = x.squeeze(1)\n",
    "\n",
    "        return x_out\n",
    "            \n",
    "    def ConvLayer(self, in_channels=32, out_channels=32, kernel_size=3,\n",
    "                  stride=1, padding=1, bias=True, relu=True, batchnorm=True):\n",
    "        layer = nn.Sequential()\n",
    "        conv = nn.Conv3d(in_channels=in_channels,\n",
    "                         out_channels=out_channels,\n",
    "                         kernel_size=kernel_size,\n",
    "                         padding=padding,\n",
    "                         bias=bias)\n",
    "        layer.add_module('conv',conv)\n",
    "        if relu:\n",
    "            layer.add_module('relu',nn.ReLU())\n",
    "        if batchnorm:\n",
    "            layer.add_module('batchnorm',nn.BatchNorm3d(out_channels))\n",
    "\n",
    "        return layer\n",
    "\n",
    "model = Unet3d()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = iou_module()\n",
    "simulator(model=model,criterion=criterion,score_fun=iou_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double U-net  \n",
    "![](extra/uu.png)  \n",
    "Taken from https://arxiv.org/pdf/1701.03056.pdf (with minor differences)  \n",
    "![](extra/myuu.png)\n",
    "* Downsampling is Conv with 2x2 kernel, stride=2.\n",
    "* Has PReLU activations.\n",
    "* Upsampling is now the transpose of downsampling.  \n",
    "![](extra/tconv.gif)\n",
    "* Uses 1d convolutions to reduce channels.   \n",
    "![](extra/1dconv.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input has shape (1, 4, 32, 32, 64).\n",
      "Target has shape (1, 32, 32, 64).\n",
      "Training output has shape (1, 32, 32, 64).\n",
      "Loss is 0.47601139545440674.\n",
      "Backward pass works.\n",
      "Evaluation output has shape (1, 32, 32, 64).\n",
      "Score is 0.498626708984375.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3d UU-net\n",
    "class Big3dU(nn.Module):\n",
    "    def __init__(self,input_channels=4):\n",
    "        super(Big3dU,self).__init__()\n",
    "        \n",
    "        self.c0 = self.ConvLayer(in_channels=4,out_channels=8,\n",
    "                                 kernel_size=3,stride=1,padding=1)\n",
    "\n",
    "        self.d1 = self.ConvLayer(in_channels=8,out_channels=16,\n",
    "                                 stride=2,kernel_size=2,padding=0)\n",
    "        self.c1 = self.ConvLayer(in_channels=16,out_channels=16,\n",
    "                                kernel_size=3,stride=1,padding=1)\n",
    "\n",
    "        self.d2 = self.ConvLayer(in_channels=16,out_channels=32,\n",
    "                                 stride=2,kernel_size=2,padding=0)\n",
    "        self.c2 = self.ConvLayer(in_channels=32,out_channels=32,\n",
    "                                kernel_size=3,stride=1,padding=1)\n",
    "\n",
    "        self.d3 = self.ConvLayer(in_channels=32,out_channels=64,\n",
    "                                 stride=2,kernel_size=2,padding=0)\n",
    "        self.c3 = self.ConvLayer(in_channels=64,out_channels=64,\n",
    "                                kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "        self.f1 = self.ConvLayer(in_channels=64,out_channels=32,\n",
    "                                kernel_size=1,stride=1,padding=0)\n",
    "        \n",
    "        self.u1 = self.ConvLayer(in_channels=32,out_channels=32,\n",
    "                                kernel_size=2,stride=2,padding=0,transpose=True)\n",
    "        self.c4 = self.ConvLayer(in_channels=64,out_channels=32,\n",
    "                                 kernel_size=3,stride=1,padding=1)\n",
    "        self.f2 = self.ConvLayer(in_channels=32,out_channels=16,\n",
    "                                kernel_size=1,stride=1,padding=0)\n",
    "        \n",
    "        self.u2 = self.ConvLayer(in_channels=16,out_channels=16,\n",
    "                                kernel_size=2,stride=2,padding=0,transpose=True)\n",
    "        self.c5 = self.ConvLayer(in_channels=32,out_channels=16,\n",
    "                                kernel_size=3,stride=1,padding=1)\n",
    "        self.f3 = self.ConvLayer(in_channels=16,out_channels=8,\n",
    "                                kernel_size=1,stride=1,padding=0)\n",
    "        \n",
    "        self.u3 = self.ConvLayer(in_channels=8,out_channels=8,\n",
    "                                kernel_size=2,stride=2,padding=0,transpose=True)\n",
    "        self.c6 = self.ConvLayer(in_channels=16,out_channels=16,\n",
    "                                kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "        self.f4 = self.ConvLayer(in_channels=32,out_channels=16,\n",
    "                                kernel_size=1,stride=1,padding=0)\n",
    "        self.f5 = self.ConvLayer(in_channels=16,out_channels=8,\n",
    "                                kernel_size=1,stride=1,padding=0)\n",
    "        self.f6 = self.ConvLayer(in_channels=16,out_channels=1,\n",
    "                                kernel_size=1,stride=1,padding=0)\n",
    "        \n",
    "        self.u4 = self.ConvLayer(in_channels=16,out_channels=8,\n",
    "                                kernel_size=2,stride=2,padding=0,transpose=True)\n",
    "        self.u5 = self.ConvLayer(in_channels=8,out_channels=1,\n",
    "                                kernel_size=2,stride=2,padding=0,transpose=True)\n",
    "        \n",
    "        self.act = nn.PReLU(num_parameters=1)  \n",
    "\n",
    "    def forward(self, x_in):\n",
    "        x0 = self.c0(x_in)\n",
    "        x1 = self.d1(x0)\n",
    "        x2 = self.c1(x1)\n",
    "        x3 = self.d2(x2+x1)\n",
    "        x4 = self.c2(x3)\n",
    "        x5 = self.d3(x4+x3)\n",
    "        x6 = self.c3(x5)\n",
    "        x7 = self.f1(x6+x5)\n",
    "        x8 = self.u1(x7)\n",
    "        x9 = self.c4(torch.cat([x8,x4],dim=1))\n",
    "        x10 = self.f2(x9)\n",
    "        x11 = self.u2(x10)\n",
    "        x12 = self.c5(torch.cat([x11,x2],dim=1))\n",
    "        x13 = self.f3(x12)\n",
    "        x14 = self.u3(x13)\n",
    "        x15 = self.f4(x9)\n",
    "        x16 = self.u4(x15)\n",
    "        x17 = self.f5(x12)\n",
    "        # x18 is missing, the graph I sketched had a box I did not use\n",
    "        x19 = self.u5(x16+x17)\n",
    "        x20 = self.c6(torch.cat([x14,x0],dim=1))\n",
    "        x21 = self.f6(x20)\n",
    "        x22 = self.act(x21+x19)\n",
    "\n",
    "        x_out = x22.squeeze(1)\n",
    "        x_out = torch.sigmoid(x_out)\n",
    "\n",
    "        return x_out\n",
    "\n",
    "    def ConvLayer(self,in_channels,out_channels,kernel_size,\n",
    "                  stride,padding,dilation=1,bias=True,prelu=True,batchnorm=True,transpose=False):\n",
    "        layer = nn.Sequential()\n",
    "        if transpose:\n",
    "            tconv = nn.ConvTranspose3d(in_channels=in_channels,\n",
    "                             out_channels=out_channels,\n",
    "                             kernel_size=kernel_size,\n",
    "                             stride=stride,\n",
    "                             padding=padding,\n",
    "                             dilation=dilation,\n",
    "                             bias=bias)\n",
    "            layer.add_module('tconv',tconv)\n",
    "        else:\n",
    "            conv = nn.Conv3d(in_channels=in_channels,\n",
    "                             out_channels=out_channels,\n",
    "                             kernel_size=kernel_size,\n",
    "                             stride=stride,\n",
    "                             padding=padding,\n",
    "                             dilation=dilation,\n",
    "                             bias=bias)\n",
    "            layer.add_module('conv',conv)\n",
    "\n",
    "        if batchnorm:\n",
    "            layer.add_module('batchnorm',nn.BatchNorm3d(num_features=out_channels))\n",
    "\n",
    "        if prelu:\n",
    "            layer.add_module('prelu',nn.PReLU(num_parameters=out_channels))\n",
    "\n",
    "        return layer\n",
    "\n",
    "model = Big3dU()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = iou_module()\n",
    "simulator(model=model,criterion=criterion,score_fun=iou_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
